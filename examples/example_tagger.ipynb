import sys
import os.path as path
sys.path.append(path.dirname(path.abspath("./")))
import tagger.src.data_reader as data_reader
import tagger.src.generate_features as generate_features
import tagger.utils.writer as data_writer
import argparse
import logging
import pickle
import numpy as np
from time import time
from sklearn.model_selection import train_test_split
from tagger.src.algorithm.CRF import CRF
curr_dir = path.dirname(path.abspath("./"))
model_type = "CRF"
language = "tel"
encoding = "utf"
data_format = "conll"
tag_type = "pos"

print('Start Training#')
print('Tagger model type: %s' % (model_type))
data_path = "%s/data/train/%s/train.%s.%s" % (curr_dir, language, encoding, data_format)
print(data_format)
data_sents = data_reader.load_data(data_format, data_path, language)
no_words = sum(len(sent) for sent in data_sents)
print("No. of words: %d" % (no_words))
print("No. of sents: %d" % (len(data_sents)))
X_data = [generate_features.sent2features(s, tag_type, model_type) for s in data_sents]
y_data = [generate_features.sent2labels(s, tag_type) for s in data_sents]
X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.10, random_state=42)
print('Train data size:', len(X_train), len(y_train))
print('Test data size:', len(X_test), len(y_test))

"""Loading CRF_tagger"""
model_path = "%s/models/%s/%s.%s.%s.model" % (curr_dir, language, model_type, tag_type, encoding)
print(y_train[0:5])
tagger = CRF(model_path)
tagger.train(X_train, y_train)
tagger.load_model()
tagger.test(X_test, y_test)
